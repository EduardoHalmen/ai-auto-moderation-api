"""Analysis of model bias.

The functions in this file expect scored data in a data frame with columns:

<text_col>: Column containing text of the example. This column name is
    passed in as a parameter of any function that needs access to it.
<label_col>: Column containing a boolean representing the example's
    true label.
<pred_col>: The model's predicted score for this example.
<subgroup>: One column per subgroup to evaluate bias for. 

    TODO?: These columns may be generated by add_subgroup_columns_from_text 
    (when being "in" a subgroup means the text contains a certain term)
"""

import base64
import io
import os
import re

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.stats as stats
import seaborn as sns
from sklearn import metrics


SUBGROUP_AUC = 'subgroup_auc'
BPSN_AUC = 'bpsn_auc'
BNSP_AUC = 'bnsp_auc'
NEGATIVE_AEG = 'negative_aeg'
POSITIVE_AEG = 'positive_aeg'

SUBGROUP_SIZE = 'subgroup_size'
SUBGROUP = 'subgroup'

METRICS = [
    SUBGROUP_AUC, BPSN_AUC, BNSP_AUC, NEGATIVE_AEG,
    POSITIVE_AEG
]
AUCS = [SUBGROUP_AUC, BPSN_AUC, BNSP_AUC]
AEGS = [NEGATIVE_AEG, POSITIVE_AEG]


def compute_auc(y_true, y_pred) -> float:
    """Computes the area under the ROC curve (AUC) for the given true and predicted labels.
    
    Parameters
    ----------
        y_true: array-like of shape (n_samples, ) - True binary labels.
        y_pred: array-like of shape (n_samples, ) - Target scores.

    Returns
    -------
        auc: float - The AUC score
    """
    try:
        return metrics.roc_auc_score(y_true, y_pred)
    except ValueError as e:
        return np.nan


def compute_subgroup_auc(df: pd.DataFrame, subgroup: str, label: str, pred_col: str) -> float:
    """Computes the AUC for a specific subgroup within the dataset.
    The dataframe must have the predicted scores and true labels for the subgroup.

    Parameters
    ----------
        df: pd.DataFrame - The DataFrame containing the data.
        subgroup: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        auc: float - The AUC score for the specified subgroup.
    """
    # Filters the DataFrame o include only specific subgroup examples
    subgroup_examples = df[df[subgroup]]
    # Computes the AUC for the subgroup
    return compute_auc(subgroup_examples[label], subgroup_examples[pred_col])


def compute_bpsn_auc(df: pd.DataFrame, subgroup: str, label: str, pred_col: str) -> float:
    """Computes the AUC of the background positive examples and the within-subgroup negative examples.
    
    Parameters
    ----------
        df: pd.DataFrame - The DataFrame containing the data.
        subgroup: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        bpsn_auc: float - The AUC score for the background positive examples and subgroup negative examples.
    """
    # Filters the DataFrame to include only the subgroup NEGATIVE examples...
    subgroup_negative_examples = df[df[subgroup] & ~df[label]]
    # And the background POSITIVE examples
    non_subgroup_positive_examples = df[~df[subgroup] & df[label]]
    examples = pd.concat([subgroup_negative_examples, non_subgroup_positive_examples])
    return compute_auc(examples[label], examples[pred_col])


def compute_bnsp_auc(df: pd.DataFrame, subgroup: str, label: str, pred_col: str) -> float:

    """Computes the AUC of the subgroup positive examples and the background negative examples.
    
    Parameters  
    ----------
    df: pd.DataFrame - The DataFrame containing the data.
        subgroup: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        bnsp_auc: float - The AUC score for the background negative examples and subgroup positive examples.
    """
    # Filters the DataFrame to include only the subgroup POSITIVE examples...
    subgroup_positive_examples = df[df[subgroup] & df[label]]
    # And the background NEGATIVE examples
    non_subgroup_negative_examples = df[~df[subgroup] & ~df[label]]
    examples = pd.concat([subgroup_positive_examples, non_subgroup_negative_examples])
    return compute_auc(examples[label], examples[pred_col])


def normalized_mwu(data1: pd.DataFrame, data2: pd.DataFrame, pred_col: str) -> float:
    """Computes the normalized Mann-Whitney U statistic between two datasets.

    Parameters
    ----------
        data1: pd.DataFrame - The first dataset.
        data2: pd.DataFrame - The second dataset.
        pred_col: str - The name of the column to compare.

    Returns
    -------
        normalized_mwu: float - The normalized Mann-Whitney U statistic.
    """
    scores_1 = data1[pred_col]
    scores_2 = data2[pred_col]

    n1 = len(scores_1)
    n2 = len(scores_2)

    if n1 == 0 or n2 == 0:
        return np.nan
    u, _ = stats.mannwhitneyu(scores_1, scores_2, alternative='less')
    
    return u / (n1 * n2)


def compute_negative_aeg(df: pd.DataFrame, subgroup: str, label: str, pred_col: str) -> float:
    """Computes the negative average exposure gain (AEG) for a specific subgroup.

    Parameters
    ----------
        df: pd.DataFrame - The DataFrame containing the data.
        subgroup: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        negative_aeg: float - The negative AEG score for the specified subgroup.
    """
    mwu = normalized_mwu(df[~df[subgroup] & ~df[label]],
                         df[df[subgroup] & ~df[label]], pred_col)
    if mwu is None:
        return np.nan
    return 0.5 - mwu


def compute_positive_aeg(df: pd.DataFrame, subgroup: str, label: str, pred_col: str) -> float:
    """Computes the positive average exposure gain (AEG) for a specific subgroup.

    Parameters
    ----------
        df: pd.DataFrame - The DataFrame containing the data.
        subgroup: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        positive_aeg: float - The positive AEG score for the specified subgroup.
    """
    mwu = normalized_mwu(df[~df[subgroup] & df[label]],
                         df[df[subgroup] & df[label]], pred_col)
    if mwu is None:
        return np.nan
    return 0.5 - mwu


def compute_bias_metrics_for_subgroup_and_model(dataset: pd.DataFrame,
                                                subgroup: str,
                                                label: str,
                                                pred_col: str) -> dict:
    """Computes bias metrics for a specific subgroup and model.

    Parameters
    ----------
        dataset: pd.DataFrame - The DataFrame containing the data.
        subgroup: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        metrics_dict: dict - A dictionary containing the computed bias metrics.
    """
    metrics_dict = {
        SUBGROUP: subgroup,
        SUBGROUP_SIZE: dataset[subgroup].sum(),
        SUBGROUP_AUC: compute_subgroup_auc(dataset, subgroup, label, pred_col),
        BPSN_AUC: compute_bpsn_auc(dataset, subgroup, label, pred_col),
        BNSP_AUC: compute_bnsp_auc(dataset, subgroup, label, pred_col),
        NEGATIVE_AEG: compute_negative_aeg(dataset, subgroup, label, pred_col),
        POSITIVE_AEG: compute_positive_aeg(dataset, subgroup, label, pred_col)
    }
    return metrics_dict


def compute_bias_metrics_for_model(dataset: pd.DataFrame,
                                   subgroups: list[str],
                                   label: str,
                                   pred_col: str) -> pd.DataFrame:
    """Computes bias metrics for a model across all subgroups in the dataset.

    Parameters
    ----------
        dataset: pd.DataFrame - The DataFrame containing the data.
        subgroup_col: str - The name of the subgroup column to filter on.
        label: str - The name of the true label column.
        pred_col: str - The name of the predicted scores column.

    Returns
    -------
        metrics_df: pd.DataFrame - A DataFrame containing the computed bias metrics for each subgroup.
    """
    metrics_list = [
        compute_bias_metrics_for_subgroup_and_model(dataset, subgroup, label, pred_col)
        for subgroup in subgroups
    ]
    return pd.DataFrame(metrics_list).sort_values(by=SUBGROUP_AUC, ascending=True)